{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Tumor MRI - Instance Segmentation - VNET - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import tensorboard\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as fn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from model import VNet\n",
    "from trainer import Trainer\n",
    "from transformations import (\n",
    "    normalize_01,\n",
    "    re_normalize, \n",
    "    transforms,\n",
    "    ComposeDouble,\n",
    "    FunctionWrapperDouble,\n",
    "    create_dense_target,\n",
    "    AlbuSeg3d,\n",
    ")\n",
    "from utils import (\n",
    "    get_filenames_of_path,\n",
    "    postprocess, \n",
    "    draw_segmentation_map, \n",
    "    segmentation_target, \n",
    "    segmentation_pred, \n",
    "    save_gif\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataSet3(data.Dataset):\n",
    "    \"\"\"Image segmentation dataset with caching, pretransforms and multiprocessing.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs: list,\n",
    "        targets: list,\n",
    "        transform=None,\n",
    "        use_cache: bool = False,\n",
    "        pre_transform=None,\n",
    "    ):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.inputs_dtype = torch.float32\n",
    "        self.targets_dtype = torch.long\n",
    "        self.use_cache = use_cache\n",
    "        self.pre_transform = pre_transform\n",
    "\n",
    "        if self.use_cache:\n",
    "            from itertools import repeat\n",
    "            from multiprocessing import Pool\n",
    "\n",
    "            with Pool() as pool:\n",
    "                self.cached_data = pool.starmap(\n",
    "                    self.read_images, zip(inputs, targets, repeat(self.pre_transform))\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if self.use_cache:\n",
    "            x, y = self.cached_data[index]\n",
    "        else:\n",
    "            # Select the sample\n",
    "            input_ID = self.inputs[index]\n",
    "            target_ID = self.targets[index]\n",
    "\n",
    "            # Load input and target\n",
    "            x, y = imread(str(input_ID)), imread(str(target_ID))\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.transform is not None:\n",
    "            x, y = self.transform(x, y)\n",
    "\n",
    "        # Typecasting\n",
    "        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)\n",
    "        return x, y\n",
    "\n",
    "    @staticmethod\n",
    "    def read_images(inp, tar, pre_transform):\n",
    "        inp, tar = imread(str(inp)), imread(str(tar))\n",
    "        if pre_transform:\n",
    "            inp, tar = pre_transform(inp, tar)\n",
    "        return inp, tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_training = ComposeDouble(\n",
    "    [\n",
    "         FunctionWrapperDouble(resize, input=True, target=False, output_shape=(16, 128, 128)),\n",
    "         FunctionWrapperDouble(resize, input=False, target=True, output_shape=(16, 128, 128), order=0, anti_aliasing=False, preserve_range=True),\n",
    "         AlbuSeg3d(albumentations.HorizontalFlip(p=0.5)),\n",
    "         AlbuSeg3d(albumentations.VerticalFlip(p=0.5)),\n",
    "         AlbuSeg3d(albumentations.Rotate(p=0.5)),\n",
    "         AlbuSeg3d(albumentations.RandomRotate90(p=0.5)),\n",
    "         FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "         FunctionWrapperDouble(np.expand_dims, axis=0),\n",
    "         #RandomFlip(ndim_spatial=3),\n",
    "         FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_testing = ComposeDouble(\n",
    "    [\n",
    "         FunctionWrapperDouble(resize, input=True, target=False, output_shape=(16, 128, 128)),\n",
    "         FunctionWrapperDouble(resize, input=False, target=True, output_shape=(16, 128, 128), order=0, anti_aliasing=False, preserve_range=True),\n",
    "         #AlbuSeg3d(albumentations.HorizontalFlip(p=0.5)),\n",
    "         #AlbuSeg3d(albumentations.VerticalFlip(p=0.5)),\n",
    "         #AlbuSeg3d(albumentations.Rotate(p=0.5)),\n",
    "         #AlbuSeg3d(albumentations.RandomRotate90(p=0.5)),\n",
    "         FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "         FunctionWrapperDouble(np.expand_dims, axis=0),\n",
    "         # RandomFlip(ndim_spatial=3),\n",
    "         FunctionWrapperDouble(normalize_01),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_train = pathlib.Path.cwd() / \"Data3D/train\"\n",
    "root_val = pathlib.Path.cwd() / \"Data3D/val\"\n",
    "\n",
    "# input and target files\n",
    "inputs_train = get_filenames_of_path(root_train / \"Input\")\n",
    "targets_train = get_filenames_of_path(root_train / \"Target\")\n",
    "\n",
    "inputs_val = get_filenames_of_path(root_val / \"Input\")\n",
    "targets_val = get_filenames_of_path(root_val / \"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset training\n",
    "dataset_train = SegmentationDataSet3(\n",
    "    inputs=inputs_train,\n",
    "    targets=targets_train,\n",
    "    transform=transforms_training,\n",
    "    use_cache=False,\n",
    "    pre_transform=None,\n",
    ")\n",
    "\n",
    "# dataset training\n",
    "dataset_val = SegmentationDataSet3(\n",
    "    inputs=inputs_val,\n",
    "    targets=targets_val,\n",
    "    transform=transforms_training,\n",
    "    use_cache=False,\n",
    "    pre_transform=None,\n",
    ")\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=1,\n",
    "    # batch_size of 2 won't work because the depth dimension is different between the 2 samples\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dataloader_validation = DataLoader(\n",
    "    dataset=dataset_val,\n",
    "    batch_size=1,\n",
    "    # batch_size of 2 won't work because the depth dimension is different between the 2 samples\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Summary Writer TensorBoard\n",
    "writer = SummaryWriter('runs/vnet')\n",
    "\n",
    "# Monai VNET model\n",
    "#model = monai.networks.nets.VNet(spatial_dims=3, in_channels=1, out_channels=3, act=('elu', {'inplace': True}), \n",
    "                                 #dropout_prob=0.5, dropout_dim=3, bias=False).to(device)\n",
    "                        \n",
    "# Paper Vnet model\n",
    "model = VNet(elu=True, in_channels=1, classes=3).to(device)\n",
    "\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses.dice import DiceLoss\n",
    "\n",
    "# Cross Entropy Loss : \n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Dice Loss : \n",
    "dice_loss = DiceLoss(reduction='mean', to_onehot_y=True, sigmoid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam : \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReduceLROnPlateau : \n",
    "plateau_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "# StepLR :  \n",
    "step_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# MultiplicativeLR : \n",
    "multiplicative_lr_scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.95) \n",
    "\n",
    "# lambdaLR :  \n",
    "lambda_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "\n",
    "# CosineLR : \n",
    "cosine_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=dice_loss,\n",
    "    optimizer=optimizer,\n",
    "    training_dataloader=dataloader_training,\n",
    "    validation_dataloader=dataloader_validation,\n",
    "    lr_scheduler=plateau_lr_scheduler,\n",
    "    epochs=500,\n",
    "    epoch=0,\n",
    "    writer = writer,\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "\n",
    "fig = plot_training(\n",
    "    training_losses,\n",
    "    validation_losses,\n",
    "    lr_rates,\n",
    "    gaussian=True,\n",
    "    sigma=1,\n",
    "    figsize=(10, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Vnet model\n",
    "model = VNet(elu=True, in_channels=1, classes=4).to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lr_rate_finder import LearningRateFinder\n",
    "\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrf.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_test = pathlib.Path.cwd() / \"Data3D/test\"\n",
    "\n",
    "# input and target files\n",
    "inputs_test = get_filenames_of_path(root_test / \"Input\")\n",
    "targets_test = get_filenames_of_path(root_test / \"Target\")\n",
    "\n",
    "dataset_test = SegmentationDataSet3(\n",
    "    inputs=inputs_test,\n",
    "    targets=targets_test,\n",
    "    transform=transforms_testing,\n",
    "    use_cache=False,\n",
    "    pre_transform=None,\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=1,\n",
    "    # batch_size of 2 won't work because the depth dimension is different between the 2 samples\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "model.eval()\n",
    "for indice, (image, mask) in enumerate(dataloader_test):\n",
    "    input_image, input_mask = image.to(device), mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image) # send through model/network\n",
    "        output = postprocess(output) # postprocess the prediction\n",
    "        \n",
    "        filepath_out_target = f'{root_test}/Segmentation/segmentation_target_{indice}.gif'\n",
    "        filepath_out_pred = f'{root_test}/Segmentation/segmentation_prediction_{indice}.gif'\n",
    "        \n",
    "        segmentation_target_path = segmentation_target(input_image, input_mask, filepath_out_target)\n",
    "        segmentation_pred_path = segmentation_pred(input_image, output, filepath_out_pred)\n",
    "        \n",
    "        with open(segmentation_target_path,'rb') as f:\n",
    "            display.Image(data=f.read(), format='png')\n",
    "\n",
    "        with open(segmentation_pred_path,'rb') as f:\n",
    "            display.Image(data=f.read(), format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name = \"brain_mri_vnet.pt\"\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m97"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
