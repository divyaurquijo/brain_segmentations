{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Tumor MRI - Instance Segmentation - UNET 3D Sclices - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import tensorboard\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as fn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from other files\n",
    "from model import UNet\n",
    "from trainer import Trainer\n",
    "from transformations import (\n",
    "    normalize_01,\n",
    "    re_normalize, \n",
    "    transforms, \n",
    "    crop_sample, \n",
    "    pad_sample, \n",
    "    resize_sample, \n",
    "    normalize_volume\n",
    ")\n",
    "from utils import (\n",
    "    predict, \n",
    "    preprocess, \n",
    "    preprocess_images,\n",
    "    postprocess, \n",
    "    draw_segmentation_map,\n",
    "    save_gif, \n",
    "    segmentation_target, \n",
    "    segmentation_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "    \"\"\"Brain MRI dataset for FLAIR abnormality segmentation\"\"\"\n",
    "\n",
    "    in_channels = 3\n",
    "    out_channels = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir,\n",
    "        transform=None,\n",
    "        image_size=256,\n",
    "        subset=\"train\",\n",
    "        random_sampling=True,\n",
    "        validation_cases=0,\n",
    "        seed=42,\n",
    "    ):\n",
    "        assert subset in [\"all\", \"train\", \"validation\"]\n",
    "\n",
    "        # read images\n",
    "        volumes = {}\n",
    "        masks = {}\n",
    "        print(\"reading {} images...\".format(subset))\n",
    "        for (dirpath, dirnames, filenames) in os.walk(images_dir):\n",
    "            image_slices = []\n",
    "            mask_slices = []\n",
    "            for filename in sorted(\n",
    "                filter(lambda f: \".tif\" in f, filenames),\n",
    "                key=lambda x: int(x.split(\".\")[-2].split(\"_\")[4]),\n",
    "            ):\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                if \"mask\" in filename:\n",
    "                    mask_slices.append(imread(filepath, as_gray=True))\n",
    "                else:\n",
    "                    image_slices.append(imread(filepath))\n",
    "                #print(\"dirpath\", dirpath.split(\"/\"))\n",
    "            if len(image_slices) > 0:\n",
    "                patient_id = dirpath.split(\"/\")[-1]\n",
    "                volumes[patient_id] = np.array(image_slices[1:-1])\n",
    "                masks[patient_id] = np.array(mask_slices[1:-1])\n",
    "                #print(\"patient_id\", patient_id, \"volumes\", len(volumes), \"masks\", len(masks))\n",
    "\n",
    "        self.patients = sorted(volumes)\n",
    "        print(\"self.patients\", self.patients)\n",
    "\n",
    "        # select cases to subset\n",
    "        if not subset == \"all\":\n",
    "            random.seed(seed)\n",
    "            validation_patients = random.sample(self.patients, k=validation_cases)\n",
    "            print(\"validation_patients\", validation_patients)\n",
    "            if subset == \"validation\":\n",
    "                self.patients = validation_patients\n",
    "            else:\n",
    "                self.patients = sorted(\n",
    "                    list(set(self.patients).difference(validation_patients))\n",
    "                )\n",
    "            print(\"self.patients\", self.patients)\n",
    "\n",
    "        print(\"preprocessing {} volumes...\".format(subset))\n",
    "        # create list of tuples (volume, mask)\n",
    "        self.volumes = [(volumes[k], masks[k]) for k in self.patients]\n",
    "\n",
    "        print(\"cropping {} volumes...\".format(subset))\n",
    "        # crop to smallest enclosing volume\n",
    "        self.volumes = [crop_sample(v) for v in self.volumes]\n",
    "\n",
    "        print(\"padding {} volumes...\".format(subset))\n",
    "        # pad to square\n",
    "        self.volumes = [pad_sample(v) for v in self.volumes]\n",
    "\n",
    "        print(\"resizing {} volumes...\".format(subset))\n",
    "        # resize\n",
    "        self.volumes = [resize_sample(v, size=image_size) for v in self.volumes]\n",
    "\n",
    "        print(\"normalizing {} volumes...\".format(subset))\n",
    "        # normalize channel-wise\n",
    "        self.volumes = [(normalize_volume(v), m) for v, m in self.volumes]\n",
    "\n",
    "        # probabilities for sampling slices based on masks\n",
    "        self.slice_weights = [m.sum(axis=-1).sum(axis=-1) for v, m in self.volumes]\n",
    "        self.slice_weights = [\n",
    "            (s + (s.sum() * 0.1 / len(s))) / (s.sum() * 1.1) for s in self.slice_weights\n",
    "        ]\n",
    "\n",
    "        # add channel dimension to masks\n",
    "        self.volumes = [(v, m[..., np.newaxis]) for (v, m) in self.volumes]\n",
    "\n",
    "        print(\"done creating {} dataset\".format(subset))\n",
    "\n",
    "        # create global index for patient and slice (idx -> (p_idx, s_idx))\n",
    "        num_slices = [v.shape[0] for v, m in self.volumes]\n",
    "        self.patient_slice_index = list(\n",
    "            zip(\n",
    "                sum([[i] * num_slices[i] for i in range(len(num_slices))], []),\n",
    "                sum([list(range(x)) for x in num_slices], []),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.random_sampling = random_sampling\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_slice_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient = self.patient_slice_index[idx][0]\n",
    "        slice_n = self.patient_slice_index[idx][1]\n",
    "\n",
    "        if self.random_sampling:\n",
    "            patient = np.random.randint(len(self.volumes))\n",
    "            slice_n = np.random.choice(\n",
    "                range(self.volumes[patient][0].shape[0]), p=self.slice_weights[patient]\n",
    "            )\n",
    "\n",
    "        v, m = self.volumes[patient]\n",
    "        image = v[slice_n]\n",
    "        mask = m[slice_n]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image, mask = self.transform((image, mask))\n",
    "\n",
    "        # fix dimensions (C, H, W)\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        mask = mask.transpose(2, 0, 1).squeeze(0)\n",
    "        \n",
    "        image = (image - np.min(image)) / np.ptp(image)\n",
    "        #print(\"np.min(mask)\", np.min(mask), \"np.ptp(mask)\", np.ptp(mask))\n",
    "        if np.ptp(mask) != 0 :\n",
    "            mask = (mask - np.min(mask)) / np.ptp(mask)\n",
    "        \n",
    "        image_tensor = torch.from_numpy(image.astype(np.float32))\n",
    "        mask_tensor = torch.from_numpy(mask.astype(np.int64))\n",
    "\n",
    "        # return tensors\n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = './Data3D/train/'\n",
    "\n",
    "# dataset training\n",
    "dataset_train = BrainSegmentationDataset(\n",
    "        images_dir=images_dir,\n",
    "        subset=\"train\",\n",
    "        image_size=128,\n",
    "        transform=transforms(scale=0.05, angle=15, flip_prob=0.5),\n",
    "        validation_cases=30,\n",
    "    )\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = BrainSegmentationDataset(\n",
    "        images_dir=images_dir,\n",
    "        subset=\"validation\",\n",
    "        image_size=128,\n",
    "        transform=transforms(scale=0.05, angle=15, flip_prob=0.5),\n",
    "        validation_cases=30,\n",
    "    )\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train, batch_size=4, shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "# Summary Writer TensorBoard\n",
    "writer = SummaryWriter('runs/unet3D')\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#Learning Rate\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "#Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#Adamax\n",
    "#optimizer = torch.optim.Adamax(model.parameters(), lr=lr)\n",
    "\n",
    "#RMSprop\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses.dice import DiceLoss, FocalLoss\n",
    "\n",
    "# Cross Entropy Loss : \n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Dice Loss : \n",
    "dice_loss = DiceLoss(reduction='mean', to_onehot_y=True, sigmoid=True)\n",
    "\n",
    "# Focal Loss : \n",
    "focal_loss = FocalLoss(reduction='mean', to_onehot_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ReduceLROnPlateau : \n",
    "plateau_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "# StepLR :  \n",
    "step_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# MultiplicativeLR : \n",
    "multiplicative_lr_scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.95) \n",
    "\n",
    "# lambdaLR :  \n",
    "lambda_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "\n",
    "# CosineLR : \n",
    "cosine_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    criterion=cross_entropy_loss,\n",
    "    optimizer=optimizer,\n",
    "    training_dataloader=dataloader_training,\n",
    "    validation_dataloader=dataloader_validation,\n",
    "    lr_scheduler=plateau_lr_scheduler,\n",
    "    epochs=50,\n",
    "    epoch=0,\n",
    "    writer = writer,\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lr_rate_finder import LearningRateFinder\n",
    "\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrf.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "root = f'./Data3D/test'\n",
    "\n",
    "test_directories = list(os.listdir(root))\n",
    "\n",
    "for directory in test_directories:\n",
    "    directory_path = os.path.join(root, directory)\n",
    "    inputs_test = os.path.join(directory_path, 'Input')\n",
    "    targets_test = os.path.join(directory_path, 'Target')\n",
    "    \n",
    "    images_res, targets_res = preprocess_images(inputs_test, targets_test)\n",
    "    # predict the segmentation maps\n",
    "    output = [predict(img, model, preprocess, postprocess, device) for img in images_res]\n",
    "    \n",
    "    # Create a segmentation array for ground truth\n",
    "    segmentation_target_path = segmentation_target(directory, directory_path, images_res, targets_res)\n",
    "    \n",
    "    # Create a segmentations array for predictions\n",
    "    segmentation_pred_path = segmentation_pred(directory, directory_path, images_res, output)\n",
    "    \n",
    "    # Display GIF images \n",
    "    with open(segmentation_target_path,'rb') as f:\n",
    "        display.Image(data=f.read(), format='png')\n",
    "\n",
    "    with open(segmentation_pred_path,'rb') as f:\n",
    "        display.Image(data=f.read(), format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name = \"brain_mri_unet3D.pt\"\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m97"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
